{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will talk about using the CSV data format for reading/writing/sharing text files. CSV stands for Comma Separated Values. It's quite flexible and compact, it's around since long time, and it's the main format used by popular spreadsheet programs such as Excel. Many data repositories make use of CSV as one their standard formats for data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"csv/excel.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file reports the monthly evolution of the Amazon's stock market prices at Nasdaq. Data are dowloaded from Yahoo! Finance https://finance.yahoo.com/quote/AMZN/history?period1=1521362028&period2=1552898028&interval=1mo&filter=history&frequency=1mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the file looks like? Let's open it with a regular text editor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"csv/amazon_emacs.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV (comma separated values) is a format commonly used to hold in a file data that\n",
    "can be naturally represented in tabular form (e.g., excel-like): \n",
    "M data records/rows, each consisting of (at most) N ordered fields/columns\n",
    "\n",
    "row 1: column 1, column 2, column 3, .... , column N\n",
    "\n",
    "row 2: column 1, column 2, column 3, .... , column N\n",
    "\n",
    "row 3: column 1, column 2, column 3, .... , column N\n",
    "\n",
    "......\n",
    "\n",
    "row M: column 1, column 2, column 3, .... , column N\n",
    "\n",
    "In practice, data is represented as matrix where each column refers to a common object\n",
    "and each row is a different data entry. \n",
    "\n",
    "Column data are separated by a given delimiter. The default delimiter is a comma, but\n",
    "other characters can be used as a delimiter\n",
    "\n",
    "E.g.: columns are metereological measurements an N different metereological stations,\n",
    "where each row reports the measures for a different day\n",
    "\n",
    "E.g.: columns are personal data, such as name, address, and ID, where each row of data\n",
    "refers to a different person\n",
    "\n",
    "E.g., each column is the student grade for a specific course, where each row reports\n",
    "the set of grades for a different student\n",
    "\n",
    "It is common, but not strictly required, that the first row/record in a csv file\n",
    "contains strings with the names/meanings of the columns (the legend for the file)\n",
    "\n",
    "E.g., name, address, id, age, sex\n",
    "\n",
    "J. Smith, Falcon Tower West-Bay, 532720 , 38, M  \n",
    "\n",
    "A. White, Tower 99 The Pearl, 33145, 29, F  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# The csv module provides a number of methods to effectively and efficiently deal with the \n",
    "# basic reading and writing operations on CSV files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/giannidicaro/.spyder-py3/csv/Mall_Customers.csv'\n",
    "file_name = file_path.split('/')[-1]\n",
    "#print(file_name)\n",
    "f_csv = open(file_path)\n",
    "csv_data = csv.reader(f_csv, delimiter=',')\n",
    "#\n",
    "# csv_data is an iterator: at each call will return the next line in the file\n",
    "# data are read into lists of strings, where each list element is a string with \n",
    "# a filed value, identified based on the given delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_csv.reader at 0x1055856d8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0: ['CustomerID', 'Gender', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)'] (length: 5)\n",
      "Row 1: ['2', '  Male', ' 21', ' 15', ' 81'] (length: 5)\n",
      "Row 2: ['4', 'Female', '23  ', '16  ', '77'] (length: 5)\n",
      "Row 3: ['6', 'Female', '22', '17', '76'] (length: 5)\n",
      "Row 4: ['8', 'Female', '23', '18', '94'] (length: 5)\n",
      "Row 5: ['10', 'Female', '30', '19', '72'] (length: 5)\n",
      "Row 6: ['12', 'Female', '35', '19', '99'] (length: 5)\n",
      "Row 7: ['14', 'Female', '24', '20', '77'] (length: 5)\n",
      "Row 8: ['16', 'Male', '22', '20', '79'] (length: 5)\n",
      "Row 9: ['18', 'Male', '20', '21', '66'] (length: 5)\n",
      "Row 10: ['20', 'Female', '35', '23', '98'] (length: 5)\n",
      "Row 11: ['22', 'Male', '25', '24', '73'] (length: 5)\n",
      "Row 12: ['24', 'Male', '31', '25', '73'] (length: 5)\n",
      "Row 13: ['26', 'Male', '29', '28', '82'] (length: 5)\n",
      "Row 14: ['28', 'Male', '35', '28', '61'] (length: 5)\n",
      "Row 15: ['30', 'Female', '23', '29', '87'] (length: 5)\n",
      "Row 16: ['32', 'Female', '21', '30', '73'] (length: 5)\n",
      "Row 17: ['34', 'Male', '18', '33', '92'] (length: 5)\n",
      "Row 18: ['36', 'Female', '21', '33', '81'] (length: 5)\n",
      "Row 19: ['38', 'Female', '30', '34', '73'] (length: 5)\n",
      "Row 20: ['40', 'Female', '20', '37', '75'] (length: 5)\n",
      "Row 21: ['42', 'Male', '24', '38', '92'] (length: 5)\n",
      "Row 22: ['44', 'Female', '31', '39', '61'] (length: 5)\n",
      "Row 23: ['46', 'Female', '24', '39', '65'] (length: 5)\n",
      "Row 24: ['48', 'Female', '27', '40', '47'] (length: 5)\n",
      "Row 25: ['50', 'Female', '31', '40', '42'] (length: 5)\n",
      "Row 26: ['52', 'Male', '33', '42', '60'] (length: 5)\n",
      "Row 27: ['54', 'Male', '59', '43', '60'] (length: 5)\n",
      "Row 28: ['56', 'Male', '47', '43', '41'] (length: 5)\n",
      "Row 29: ['58', 'Male', '69', '44', '46'] (length: 5)\n",
      "Row 30: ['60', 'Male', '53', '46', '46'] (length: 5)\n",
      "Row 31: ['62', 'Male', '19', '46', '55'] (length: 5)\n",
      "Row 32: ['64', 'Female', '54', '47', '59'] (length: 5)\n",
      "Row 33: ['66', 'Male', '18', '48', '59'] (length: 5)\n",
      "Row 34: ['68', 'Female', '68', '48', '48'] (length: 5)\n",
      "Row 35: ['70', 'Female', '32', '48', '47'] (length: 5)\n",
      "Row 36: ['72', 'Female', '47', '49', '42'] (length: 5)\n",
      "Row 37: ['74', 'Female', '60', '50', '56'] (length: 5)\n",
      "Row 38: ['76', 'Male', '26', '54', '54'] (length: 5)\n",
      "Row 39: ['78', 'Male', '40', '54', '48'] (length: 5)\n",
      "Row 40: ['80', 'Female', '49', '54', '42'] (length: 5)\n",
      "Row 41: ['82', 'Male', '38', '54', '55'] (length: 5)\n",
      "Row 42: ['84', 'Female', '46', '54', '44'] (length: 5)\n",
      "Row 43: ['86', 'Male', '48', '54', '46'] (length: 5)\n",
      "Row 44: ['88', 'Female', '22', '57', '55'] (length: 5)\n",
      "Row 45: ['90', 'Female', '50', '58', '46'] (length: 5)\n",
      "Row 46: ['92', 'Male', '18', '59', '41'] (length: 5)\n",
      "Row 47: ['94', 'Female', '40', '60', '40'] (length: 5)\n",
      "Row 48: ['96', 'Male', '24', '60', '52'] (length: 5)\n",
      "Row 49: ['98', 'Female', '27', '60', '50'] (length: 5)\n",
      "Row 50: ['100', 'Male', '20', '61', '49'] (length: 5)\n",
      "Row 51: ['102', 'Female', '49', '62', '48'] (length: 5)\n",
      "Row 52: ['104', 'Male', '26', '62', '55'] (length: 5)\n",
      "Row 53: ['106', 'Female', '21', '62', '42'] (length: 5)\n",
      "Row 54: ['108', 'Male', '54', '63', '46'] (length: 5)\n",
      "Row 55: ['110', 'Male', '66', '63', '48'] (length: 5)\n",
      "Row 56: ['112', 'Female', '19', '63', '54'] (length: 5)\n",
      "Row 57: ['114', 'Male', '19', '64', '46'] (length: 5)\n",
      "Row 58: ['116', 'Female', '19', '65', '50'] (length: 5)\n",
      "Row 59: ['118', 'Female', '49', '65', '59'] (length: 5)\n",
      "Row 60: ['120', 'Female', '50', '67', '57'] (length: 5)\n",
      "Row 61: ['122', 'Female', '38', '67', '40'] (length: 5)\n",
      "Row 62: ['124', 'Male', '39', '69', '91'] (length: 5)\n",
      "Row 63: ['126', 'Female', '31', '70', '77'] (length: 5)\n",
      "Row 64: ['128', 'Male', '40', '71', '95'] (length: 5)\n",
      "Row 65: ['130', 'Male', '38', '71', '75'] (length: 5)\n",
      "Row 66: ['132', 'Male', '39', '71', '75'] (length: 5)\n",
      "Row 67: ['134', 'Female', '31', '72', '71'] (length: 5)\n",
      "Row 68: ['136', 'Female', '29', '73', '88'] (length: 5)\n",
      "Row 69: ['138', 'Male', '32', '73', '73'] (length: 5)\n",
      "Row 70: ['140', 'Female', '35', '74', '72'] (length: 5)\n",
      "Row 71: ['142', 'Male', '32', '75', '93'] (length: 5)\n",
      "Row 72: ['144', 'Female', '32', '76', '87'] (length: 5)\n",
      "Row 73: ['146', 'Male', '28', '77', '97'] (length: 5)\n",
      "Row 74: ['148', 'Female', '32', '77', '74'] (length: 5)\n",
      "Row 75: ['150', 'Male', '34', '78', '90'] (length: 5)\n",
      "Row 76: ['152', 'Male', '39', '78', '88'] (length: 5)\n",
      "Row 77: ['154', 'Female', '38', '78', '76'] (length: 5)\n",
      "Row 78: ['156', 'Female', '27', '78', '89'] (length: 5)\n",
      "Row 79: ['158', 'Female', '30', '78', '78'] (length: 5)\n",
      "Row 80: ['160', 'Female', '30', '78', '73'] (length: 5)\n",
      "Row 81: ['162', 'Female', '29', '79', '83'] (length: 5)\n",
      "Row 82: ['164', 'Female', '31', '81', '93'] (length: 5)\n",
      "Row 83: ['166', 'Female', '36', '85', '75'] (length: 5)\n",
      "Row 84: ['168', 'Female', '33', '86', '95'] (length: 5)\n",
      "Row 85: ['170', 'Male', '32', '87', '63'] (length: 5)\n",
      "Row 86: ['172', 'Male', '28', '87', '75'] (length: 5)\n",
      "Row 87: ['174', 'Male', '36', '87', '92'] (length: 5)\n",
      "Row 88: ['176', 'Female', '30', '88', '86'] (length: 5)\n",
      "Row 89: ['178', 'Male', '27', '88', '69'] (length: 5)\n",
      "Row 90: ['180', 'Male', '35', '93', '90'] (length: 5)\n",
      "Row 91: ['182', 'Female', '32', '97', '86'] (length: 5)\n",
      "Row 92: ['184', 'Female', '29', '98', '88'] (length: 5)\n",
      "Row 93: ['186', 'Male', '30', '99', '97'] (length: 5)\n",
      "Row 94: ['188', 'Male', '28', '101', '68'] (length: 5)\n",
      "Row 95: ['190', 'Female', '36', '103', '85'] (length: 5)\n",
      "Row 96: ['192', 'Female', '32', '103', '69'] (length: 5)\n",
      "Row 97: ['194', 'Female', '38', '113', '91'] (length: 5)\n",
      "Row 98: ['196', 'Female', '35', '120', '79'] (length: 5)\n",
      "Row 99: ['198', 'Male', '32', '126', '74'] (length: 5)\n",
      "Row 100: ['200', 'Male', '30', '137', '83'] (length: 5)\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f141f8c17dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Row {:d}: {} (length: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# another way to make the same print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#print('Line: {}'.format(' - '.join(row)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#f = open(file_path)\n",
    "#cnt = 0\n",
    "#for ff in f:\n",
    "#    print(ff)\n",
    "#    cnt += 1\n",
    "#    if cnt > 10:\n",
    "#        break\n",
    "\n",
    "f_csv.seek(0)\n",
    "# Let's print out what's in the file\n",
    "line_count = 0\n",
    "for row in csv_data:\n",
    "    print('Row {:d}: {} (length: {})'.format(line_count, row, len(row)))\n",
    "    next(csv_data)\n",
    "    # another way to make the same print\n",
    "    #print('Line: {}'.format(' - '.join(row)))\n",
    "    line_count += 1\n",
    "# it looks like most of the column fields are nicely separated by commas, but som fields\n",
    "# have extra spaces: should we worry about it? Let's re-read the file and let's use the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv.reader() is an iterator: we have already reached the end, therefore, if we want\n",
    "# to read it again, we have to restart from the beginning\n",
    "# The function line = next(f_csv) can be used for to go to the next line, \n",
    "# it returns the current line\n",
    "f_csv.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Mall_Customers.csv contains 5 columns: CustomerID - Gender - Age - Annual Income (k$) - Spending Score (1-100)\n",
      "ID 1 is a   Male of 19 years making  15$/year and has a spending score of  39\n",
      "ID 2 is a   Male of 21 years making  15$/year and has a spending score of  81\n",
      "ID 3 is a    Female    of 20 years making  16$/year and has a spending score of   6\n",
      "ID 4 is a Female of 23 years making  16$/year and has a spending score of  77\n",
      "ID 5 is a Female of 31 years making  17$/year and has a spending score of  40\n",
      "ID 6 is a Female of 22 years making  17$/year and has a spending score of  76\n",
      "ID 7 is a Female of 35 years making  18$/year and has a spending score of   6\n",
      "ID 8 is a Female of 23 years making  18$/year and has a spending score of  94\n",
      "ID 9 is a   Male of 64 years making  19$/year and has a spending score of   3\n",
      "ID 10 is a Female of 30 years making  19$/year and has a spending score of  72\n",
      "ID 11 is a   Male of 67 years making  19$/year and has a spending score of  14\n",
      "ID 12 is a Female of 35 years making  19$/year and has a spending score of  99\n",
      "ID 13 is a Female of 58 years making  20$/year and has a spending score of  15\n",
      "ID 14 is a Female of 24 years making  20$/year and has a spending score of  77\n",
      "ID 15 is a   Male of 37 years making  20$/year and has a spending score of  13\n",
      "ID 16 is a   Male of 22 years making  20$/year and has a spending score of  79\n",
      "ID 17 is a Female of 35 years making  21$/year and has a spending score of  35\n",
      "ID 18 is a   Male of 20 years making  21$/year and has a spending score of  66\n",
      "ID 19 is a   Male of 52 years making  23$/year and has a spending score of  29\n",
      "ID 20 is a Female of 35 years making  23$/year and has a spending score of  98\n",
      "ID 21 is a   Male of 35 years making  24$/year and has a spending score of  35\n",
      "ID 22 is a   Male of 25 years making  24$/year and has a spending score of  73\n",
      "ID 23 is a Female of 46 years making  25$/year and has a spending score of   5\n",
      "ID 24 is a   Male of 31 years making  25$/year and has a spending score of  73\n",
      "ID 25 is a Female of 54 years making  28$/year and has a spending score of  14\n",
      "ID 26 is a   Male of 29 years making  28$/year and has a spending score of  82\n",
      "ID 27 is a Female of 45 years making  28$/year and has a spending score of  32\n",
      "ID 28 is a   Male of 35 years making  28$/year and has a spending score of  61\n",
      "ID 29 is a Female of 40 years making  29$/year and has a spending score of  31\n",
      "ID 30 is a Female of 23 years making  29$/year and has a spending score of  87\n",
      "ID 31 is a   Male of 60 years making  30$/year and has a spending score of   4\n",
      "ID 32 is a Female of 21 years making  30$/year and has a spending score of  73\n",
      "ID 33 is a   Male of 53 years making  33$/year and has a spending score of   4\n",
      "ID 34 is a   Male of 18 years making  33$/year and has a spending score of  92\n",
      "ID 35 is a Female of 49 years making  33$/year and has a spending score of  14\n",
      "ID 36 is a Female of 21 years making  33$/year and has a spending score of  81\n",
      "ID 37 is a Female of 42 years making  34$/year and has a spending score of  17\n",
      "ID 38 is a Female of 30 years making  34$/year and has a spending score of  73\n",
      "ID 39 is a Female of 36 years making  37$/year and has a spending score of  26\n",
      "ID 40 is a Female of 20 years making  37$/year and has a spending score of  75\n",
      "ID 41 is a Female of 65 years making  38$/year and has a spending score of  35\n",
      "ID 42 is a   Male of 24 years making  38$/year and has a spending score of  92\n",
      "ID 43 is a   Male of 48 years making  39$/year and has a spending score of  36\n",
      "ID 44 is a Female of 31 years making  39$/year and has a spending score of  61\n",
      "ID 45 is a Female of 49 years making  39$/year and has a spending score of  28\n",
      "ID 46 is a Female of 24 years making  39$/year and has a spending score of  65\n",
      "ID 47 is a Female of 50 years making  40$/year and has a spending score of  55\n",
      "ID 48 is a Female of 27 years making  40$/year and has a spending score of  47\n",
      "ID 49 is a Female of 29 years making  40$/year and has a spending score of  42\n",
      "ID 50 is a Female of 31 years making  40$/year and has a spending score of  42\n",
      "ID 51 is a Female of 49 years making  42$/year and has a spending score of  52\n",
      "ID 52 is a   Male of 33 years making  42$/year and has a spending score of  60\n",
      "ID 53 is a Female of 31 years making  43$/year and has a spending score of  54\n",
      "ID 54 is a   Male of 59 years making  43$/year and has a spending score of  60\n",
      "ID 55 is a Female of 50 years making  43$/year and has a spending score of  45\n",
      "ID 56 is a   Male of 47 years making  43$/year and has a spending score of  41\n",
      "ID 57 is a Female of 51 years making  44$/year and has a spending score of  50\n",
      "ID 58 is a   Male of 69 years making  44$/year and has a spending score of  46\n",
      "ID 59 is a Female of 27 years making  46$/year and has a spending score of  51\n",
      "ID 60 is a   Male of 53 years making  46$/year and has a spending score of  46\n",
      "ID 61 is a   Male of 70 years making  46$/year and has a spending score of  56\n",
      "ID 62 is a   Male of 19 years making  46$/year and has a spending score of  55\n",
      "ID 63 is a Female of 67 years making  47$/year and has a spending score of  52\n",
      "ID 64 is a Female of 54 years making  47$/year and has a spending score of  59\n",
      "ID 65 is a   Male of 63 years making  48$/year and has a spending score of  51\n",
      "ID 66 is a   Male of 18 years making  48$/year and has a spending score of  59\n",
      "ID 67 is a Female of 43 years making  48$/year and has a spending score of  50\n",
      "ID 68 is a Female of 68 years making  48$/year and has a spending score of  48\n",
      "ID 69 is a   Male of 19 years making  48$/year and has a spending score of  59\n",
      "ID 70 is a Female of 32 years making  48$/year and has a spending score of  47\n",
      "ID 71 is a   Male of 70 years making  49$/year and has a spending score of  55\n",
      "ID 72 is a Female of 47 years making  49$/year and has a spending score of  42\n",
      "ID 73 is a Female of 60 years making  50$/year and has a spending score of  49\n",
      "ID 74 is a Female of 60 years making  50$/year and has a spending score of  56\n",
      "ID 75 is a   Male of 59 years making  54$/year and has a spending score of  47\n",
      "ID 76 is a   Male of 26 years making  54$/year and has a spending score of  54\n",
      "ID 77 is a Female of 45 years making  54$/year and has a spending score of  53\n",
      "ID 78 is a   Male of 40 years making  54$/year and has a spending score of  48\n",
      "ID 79 is a Female of 23 years making  54$/year and has a spending score of  52\n",
      "ID 80 is a Female of 49 years making  54$/year and has a spending score of  42\n",
      "ID 81 is a   Male of 57 years making  54$/year and has a spending score of  51\n",
      "ID 82 is a   Male of 38 years making  54$/year and has a spending score of  55\n",
      "ID 83 is a   Male of 67 years making  54$/year and has a spending score of  41\n",
      "ID 84 is a Female of 46 years making  54$/year and has a spending score of  44\n",
      "ID 85 is a Female of 21 years making  54$/year and has a spending score of  57\n",
      "ID 86 is a   Male of 48 years making  54$/year and has a spending score of  46\n",
      "ID 87 is a Female of 55 years making  57$/year and has a spending score of  58\n",
      "ID 88 is a Female of 22 years making  57$/year and has a spending score of  55\n",
      "ID 89 is a Female of 34 years making  58$/year and has a spending score of  60\n",
      "ID 90 is a Female of 50 years making  58$/year and has a spending score of  46\n",
      "ID 91 is a Female of 68 years making  59$/year and has a spending score of  55\n",
      "ID 92 is a   Male of 18 years making  59$/year and has a spending score of  41\n",
      "ID 93 is a   Male of 48 years making  60$/year and has a spending score of  49\n",
      "ID 94 is a Female of 40 years making  60$/year and has a spending score of  40\n",
      "ID 95 is a Female of 32 years making  60$/year and has a spending score of  42\n",
      "ID 96 is a   Male of 24 years making  60$/year and has a spending score of  52\n",
      "ID 97 is a Female of 47 years making  60$/year and has a spending score of  47\n",
      "ID 98 is a Female of 27 years making  60$/year and has a spending score of  50\n",
      "ID 99 is a   Male of 48 years making  61$/year and has a spending score of  42\n",
      "ID 100 is a   Male of 20 years making  61$/year and has a spending score of  49\n",
      "ID 101 is a Female of 23 years making  62$/year and has a spending score of  41\n",
      "ID 102 is a Female of 49 years making  62$/year and has a spending score of  48\n",
      "ID 103 is a   Male of 67 years making  62$/year and has a spending score of  59\n",
      "ID 104 is a   Male of 26 years making  62$/year and has a spending score of  55\n",
      "ID 105 is a   Male of 49 years making  62$/year and has a spending score of  56\n",
      "ID 106 is a Female of 21 years making  62$/year and has a spending score of  42\n",
      "ID 107 is a Female of 66 years making  63$/year and has a spending score of  50\n",
      "ID 108 is a   Male of 54 years making  63$/year and has a spending score of  46\n",
      "ID 109 is a   Male of 68 years making  63$/year and has a spending score of  43\n",
      "ID 110 is a   Male of 66 years making  63$/year and has a spending score of  48\n",
      "ID 111 is a   Male of 65 years making  63$/year and has a spending score of  52\n",
      "ID 112 is a Female of 19 years making  63$/year and has a spending score of  54\n",
      "ID 113 is a Female of 38 years making  64$/year and has a spending score of  42\n",
      "ID 114 is a   Male of 19 years making  64$/year and has a spending score of  46\n",
      "ID 115 is a Female of 18 years making  65$/year and has a spending score of  48\n",
      "ID 116 is a Female of 19 years making  65$/year and has a spending score of  50\n",
      "ID 117 is a Female of 63 years making  65$/year and has a spending score of  43\n",
      "ID 118 is a Female of 49 years making  65$/year and has a spending score of  59\n",
      "ID 119 is a Female of 51 years making  67$/year and has a spending score of  43\n",
      "ID 120 is a Female of 50 years making  67$/year and has a spending score of  57\n",
      "ID 121 is a   Male of 27 years making  67$/year and has a spending score of  56\n",
      "ID 122 is a Female of 38 years making  67$/year and has a spending score of  40\n",
      "ID 123 is a Female of 40 years making  69$/year and has a spending score of  58\n",
      "ID 124 is a   Male of 39 years making  69$/year and has a spending score of  91\n",
      "ID 125 is a Female of 23 years making  70$/year and has a spending score of  29\n",
      "ID 126 is a Female of 31 years making  70$/year and has a spending score of  77\n",
      "ID 127 is a   Male of 43 years making  71$/year and has a spending score of  35\n",
      "ID 128 is a   Male of 40 years making  71$/year and has a spending score of  95\n",
      "ID 129 is a   Male of 59 years making  71$/year and has a spending score of  11\n",
      "ID 130 is a   Male of 38 years making  71$/year and has a spending score of  75\n",
      "ID 131 is a   Male of 47 years making  71$/year and has a spending score of   9\n",
      "ID 132 is a   Male of 39 years making  71$/year and has a spending score of  75\n",
      "ID 133 is a Female of 25 years making  72$/year and has a spending score of  34\n",
      "ID 134 is a Female of 31 years making  72$/year and has a spending score of  71\n",
      "ID 135 is a   Male of 20 years making  73$/year and has a spending score of   5\n",
      "ID 136 is a Female of 29 years making  73$/year and has a spending score of  88\n",
      "ID 137 is a Female of 44 years making  73$/year and has a spending score of   7\n",
      "ID 138 is a   Male of 32 years making  73$/year and has a spending score of  73\n",
      "ID 139 is a   Male of 19 years making  74$/year and has a spending score of  10\n",
      "ID 140 is a Female of 35 years making  74$/year and has a spending score of  72\n",
      "ID 141 is a Female of 57 years making  75$/year and has a spending score of   5\n",
      "ID 142 is a   Male of 32 years making  75$/year and has a spending score of  93\n",
      "ID 143 is a Female of 28 years making  76$/year and has a spending score of  40\n",
      "ID 144 is a Female of 32 years making  76$/year and has a spending score of  87\n",
      "ID 145 is a   Male of 25 years making  77$/year and has a spending score of  12\n",
      "ID 146 is a   Male of 28 years making  77$/year and has a spending score of  97\n",
      "ID 147 is a   Male of 48 years making  77$/year and has a spending score of  36\n",
      "ID 148 is a Female of 32 years making  77$/year and has a spending score of  74\n",
      "ID 149 is a Female of 34 years making  78$/year and has a spending score of  22\n",
      "ID 150 is a   Male of 34 years making  78$/year and has a spending score of  90\n",
      "ID 151 is a   Male of 43 years making  78$/year and has a spending score of  17\n",
      "ID 152 is a   Male of 39 years making  78$/year and has a spending score of  88\n",
      "ID 153 is a Female of 44 years making  78$/year and has a spending score of  20\n",
      "ID 154 is a Female of 38 years making  78$/year and has a spending score of  76\n",
      "ID 155 is a Female of 47 years making  78$/year and has a spending score of  16\n",
      "ID 156 is a Female of 27 years making  78$/year and has a spending score of  89\n",
      "ID 157 is a   Male of 37 years making  78$/year and has a spending score of   1\n",
      "ID 158 is a Female of 30 years making  78$/year and has a spending score of  78\n",
      "ID 159 is a   Male of 34 years making  78$/year and has a spending score of   1\n",
      "ID 160 is a Female of 30 years making  78$/year and has a spending score of  73\n",
      "ID 161 is a Female of 56 years making  79$/year and has a spending score of  35\n",
      "ID 162 is a Female of 29 years making  79$/year and has a spending score of  83\n",
      "ID 163 is a   Male of 19 years making  81$/year and has a spending score of   5\n",
      "ID 164 is a Female of 31 years making  81$/year and has a spending score of  93\n",
      "ID 165 is a   Male of 50 years making  85$/year and has a spending score of  26\n",
      "ID 166 is a Female of 36 years making  85$/year and has a spending score of  75\n",
      "ID 167 is a   Male of 42 years making  86$/year and has a spending score of  20\n",
      "ID 168 is a Female of 33 years making  86$/year and has a spending score of  95\n",
      "ID 169 is a Female of 36 years making  87$/year and has a spending score of  27\n",
      "ID 170 is a   Male of 32 years making  87$/year and has a spending score of  63\n",
      "ID 171 is a   Male of 40 years making  87$/year and has a spending score of  13\n",
      "ID 172 is a   Male of 28 years making  87$/year and has a spending score of  75\n",
      "ID 173 is a   Male of 36 years making  87$/year and has a spending score of  10\n",
      "ID 174 is a   Male of 36 years making  87$/year and has a spending score of  92\n",
      "ID 175 is a Female of 52 years making  88$/year and has a spending score of  13\n",
      "ID 176 is a Female of 30 years making  88$/year and has a spending score of  86\n",
      "ID 177 is a   Male of 58 years making  88$/year and has a spending score of  15\n",
      "ID 178 is a   Male of 27 years making  88$/year and has a spending score of  69\n",
      "ID 179 is a   Male of 59 years making  93$/year and has a spending score of  14\n",
      "ID 180 is a   Male of 35 years making  93$/year and has a spending score of  90\n",
      "ID 181 is a Female of 37 years making  97$/year and has a spending score of  32\n",
      "ID 182 is a Female of 32 years making  97$/year and has a spending score of  86\n",
      "ID 183 is a   Male of 46 years making  98$/year and has a spending score of  15\n",
      "ID 184 is a Female of 29 years making  98$/year and has a spending score of  88\n",
      "ID 185 is a Female of 41 years making  99$/year and has a spending score of  39\n",
      "ID 186 is a   Male of 30 years making  99$/year and has a spending score of  97\n",
      "ID 187 is a Female of 54 years making 101$/year and has a spending score of  24\n",
      "ID 188 is a   Male of 28 years making 101$/year and has a spending score of  68\n",
      "ID 189 is a Female of 41 years making 103$/year and has a spending score of  17\n",
      "ID 190 is a Female of 36 years making 103$/year and has a spending score of  85\n",
      "ID 191 is a Female of 34 years making 103$/year and has a spending score of  23\n",
      "ID 192 is a Female of 32 years making 103$/year and has a spending score of  69\n",
      "ID 193 is a   Male of 33 years making 113$/year and has a spending score of   8\n",
      "ID 194 is a Female of 38 years making 113$/year and has a spending score of  91\n",
      "ID 195 is a Female of 47 years making 120$/year and has a spending score of  16\n",
      "ID 196 is a Female of 35 years making 120$/year and has a spending score of  79\n",
      "ID 197 is a Female of 45 years making 126$/year and has a spending score of  28\n",
      "ID 198 is a   Male of 32 years making 126$/year and has a spending score of  74\n",
      "ID 199 is a   Male of 32 years making 137$/year and has a spending score of  18\n",
      "ID 200 is a   Male of 30 years making 137$/year and has a spending score of  83\n"
     ]
    }
   ],
   "source": [
    "# this time let's get more info about the file and let's print output in a more structured way\n",
    "line_count = 0\n",
    "for row in csv_data:\n",
    "    if line_count == 0:\n",
    "        columns = len(row)\n",
    "        print('File {} contains {:d} columns: {:s}'.format(file_name, columns, ' - '.join(row)))\n",
    "    else:\n",
    "        print('ID {} is a {:>6s} of {:2d} years making {:3d}$/year and has \\\n",
    "a spending score of {:3d}'.format(int(row[0]), row[1], int(row[2]), \n",
    "              int(row[3]), int(row[4])))\n",
    "    line_count += 1\n",
    "f_csv.close()\n",
    "# output is correct: the int() function does a good job getting rid of all extra spaces \n",
    "# however, extra spaces in string fields stay there, because a space is a valid character!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: CustomerID Gender Age Annual Income (k$) Spending Score (1-100)\n",
      "Line: 1  Male   19  15  39\n",
      "Line: 2   Male  21  15  81\n",
      "Line: 3    Female    20 16 6\n",
      "Line: 4 Female 23   16   77\n",
      "Line: 5 Female 31 17 40\n",
      "Line: 6 Female 22 17 76\n",
      "Line: 7 Female 35 18 6\n",
      "Line: 8 Female 23 18 94\n",
      "Line: 9 Male 64 19 3\n",
      "Line: 10 Female 30 19 72\n",
      "Line: 11 Male 67 19 14\n",
      "Line: 12 Female 35 19 99\n",
      "Line: 13 Female 58 20 15\n",
      "Line: 14 Female 24 20 77\n",
      "Line: 15 Male 37 20 13\n",
      "Line: 16 Male 22 20 79\n",
      "Line: 17 Female 35 21 35\n",
      "Line: 18 Male 20 21 66\n",
      "Line: 19 Male 52 23 29\n",
      "Line: 20 Female 35 23 98\n",
      "Line: 21 Male 35 24 35\n",
      "Line: 22 Male 25 24 73\n",
      "Line: 23 Female 46 25 5\n",
      "Line: 24 Male 31 25 73\n",
      "Line: 25 Female 54 28 14\n",
      "Line: 26 Male 29 28 82\n",
      "Line: 27 Female 45 28 32\n",
      "Line: 28 Male 35 28 61\n",
      "Line: 29 Female 40 29 31\n",
      "Line: 30 Female 23 29 87\n",
      "Line: 31 Male 60 30 4\n",
      "Line: 32 Female 21 30 73\n",
      "Line: 33 Male 53 33 4\n",
      "Line: 34 Male 18 33 92\n",
      "Line: 35 Female 49 33 14\n",
      "Line: 36 Female 21 33 81\n",
      "Line: 37 Female 42 34 17\n",
      "Line: 38 Female 30 34 73\n",
      "Line: 39 Female 36 37 26\n",
      "Line: 40 Female 20 37 75\n",
      "Line: 41 Female 65 38 35\n",
      "Line: 42 Male 24 38 92\n",
      "Line: 43 Male 48 39 36\n",
      "Line: 44 Female 31 39 61\n",
      "Line: 45 Female 49 39 28\n",
      "Line: 46 Female 24 39 65\n",
      "Line: 47 Female 50 40 55\n",
      "Line: 48 Female 27 40 47\n",
      "Line: 49 Female 29 40 42\n",
      "Line: 50 Female 31 40 42\n",
      "Line: 51 Female 49 42 52\n",
      "Line: 52 Male 33 42 60\n",
      "Line: 53 Female 31 43 54\n",
      "Line: 54 Male 59 43 60\n",
      "Line: 55 Female 50 43 45\n",
      "Line: 56 Male 47 43 41\n",
      "Line: 57 Female 51 44 50\n",
      "Line: 58 Male 69 44 46\n",
      "Line: 59 Female 27 46 51\n",
      "Line: 60 Male 53 46 46\n",
      "Line: 61 Male 70 46 56\n",
      "Line: 62 Male 19 46 55\n",
      "Line: 63 Female 67 47 52\n",
      "Line: 64 Female 54 47 59\n",
      "Line: 65 Male 63 48 51\n",
      "Line: 66 Male 18 48 59\n",
      "Line: 67 Female 43 48 50\n",
      "Line: 68 Female 68 48 48\n",
      "Line: 69 Male 19 48 59\n",
      "Line: 70 Female 32 48 47\n",
      "Line: 71 Male 70 49 55\n",
      "Line: 72 Female 47 49 42\n",
      "Line: 73 Female 60 50 49\n",
      "Line: 74 Female 60 50 56\n",
      "Line: 75 Male 59 54 47\n",
      "Line: 76 Male 26 54 54\n",
      "Line: 77 Female 45 54 53\n",
      "Line: 78 Male 40 54 48\n",
      "Line: 79 Female 23 54 52\n",
      "Line: 80 Female 49 54 42\n",
      "Line: 81 Male 57 54 51\n",
      "Line: 82 Male 38 54 55\n",
      "Line: 83 Male 67 54 41\n",
      "Line: 84 Female 46 54 44\n",
      "Line: 85 Female 21 54 57\n",
      "Line: 86 Male 48 54 46\n",
      "Line: 87 Female 55 57 58\n",
      "Line: 88 Female 22 57 55\n",
      "Line: 89 Female 34 58 60\n",
      "Line: 90 Female 50 58 46\n",
      "Line: 91 Female 68 59 55\n",
      "Line: 92 Male 18 59 41\n",
      "Line: 93 Male 48 60 49\n",
      "Line: 94 Female 40 60 40\n",
      "Line: 95 Female 32 60 42\n",
      "Line: 96 Male 24 60 52\n",
      "Line: 97 Female 47 60 47\n",
      "Line: 98 Female 27 60 50\n",
      "Line: 99 Male 48 61 42\n",
      "Line: 100 Male 20 61 49\n",
      "Line: 101 Female 23 62 41\n",
      "Line: 102 Female 49 62 48\n",
      "Line: 103 Male 67 62 59\n",
      "Line: 104 Male 26 62 55\n",
      "Line: 105 Male 49 62 56\n",
      "Line: 106 Female 21 62 42\n",
      "Line: 107 Female 66 63 50\n",
      "Line: 108 Male 54 63 46\n",
      "Line: 109 Male 68 63 43\n",
      "Line: 110 Male 66 63 48\n",
      "Line: 111 Male 65 63 52\n",
      "Line: 112 Female 19 63 54\n",
      "Line: 113 Female 38 64 42\n",
      "Line: 114 Male 19 64 46\n",
      "Line: 115 Female 18 65 48\n",
      "Line: 116 Female 19 65 50\n",
      "Line: 117 Female 63 65 43\n",
      "Line: 118 Female 49 65 59\n",
      "Line: 119 Female 51 67 43\n",
      "Line: 120 Female 50 67 57\n",
      "Line: 121 Male 27 67 56\n",
      "Line: 122 Female 38 67 40\n",
      "Line: 123 Female 40 69 58\n",
      "Line: 124 Male 39 69 91\n",
      "Line: 125 Female 23 70 29\n",
      "Line: 126 Female 31 70 77\n",
      "Line: 127 Male 43 71 35\n",
      "Line: 128 Male 40 71 95\n",
      "Line: 129 Male 59 71 11\n",
      "Line: 130 Male 38 71 75\n",
      "Line: 131 Male 47 71 9\n",
      "Line: 132 Male 39 71 75\n",
      "Line: 133 Female 25 72 34\n",
      "Line: 134 Female 31 72 71\n",
      "Line: 135 Male 20 73 5\n",
      "Line: 136 Female 29 73 88\n",
      "Line: 137 Female 44 73 7\n",
      "Line: 138 Male 32 73 73\n",
      "Line: 139 Male 19 74 10\n",
      "Line: 140 Female 35 74 72\n",
      "Line: 141 Female 57 75 5\n",
      "Line: 142 Male 32 75 93\n",
      "Line: 143 Female 28 76 40\n",
      "Line: 144 Female 32 76 87\n",
      "Line: 145 Male 25 77 12\n",
      "Line: 146 Male 28 77 97\n",
      "Line: 147 Male 48 77 36\n",
      "Line: 148 Female 32 77 74\n",
      "Line: 149 Female 34 78 22\n",
      "Line: 150 Male 34 78 90\n",
      "Line: 151 Male 43 78 17\n",
      "Line: 152 Male 39 78 88\n",
      "Line: 153 Female 44 78 20\n",
      "Line: 154 Female 38 78 76\n",
      "Line: 155 Female 47 78 16\n",
      "Line: 156 Female 27 78 89\n",
      "Line: 157 Male 37 78 1\n",
      "Line: 158 Female 30 78 78\n",
      "Line: 159 Male 34 78 1\n",
      "Line: 160 Female 30 78 73\n",
      "Line: 161 Female 56 79 35\n",
      "Line: 162 Female 29 79 83\n",
      "Line: 163 Male 19 81 5\n",
      "Line: 164 Female 31 81 93\n",
      "Line: 165 Male 50 85 26\n",
      "Line: 166 Female 36 85 75\n",
      "Line: 167 Male 42 86 20\n",
      "Line: 168 Female 33 86 95\n",
      "Line: 169 Female 36 87 27\n",
      "Line: 170 Male 32 87 63\n",
      "Line: 171 Male 40 87 13\n",
      "Line: 172 Male 28 87 75\n",
      "Line: 173 Male 36 87 10\n",
      "Line: 174 Male 36 87 92\n",
      "Line: 175 Female 52 88 13\n",
      "Line: 176 Female 30 88 86\n",
      "Line: 177 Male 58 88 15\n",
      "Line: 178 Male 27 88 69\n",
      "Line: 179 Male 59 93 14\n",
      "Line: 180 Male 35 93 90\n",
      "Line: 181 Female 37 97 32\n",
      "Line: 182 Female 32 97 86\n",
      "Line: 183 Male 46 98 15\n",
      "Line: 184 Female 29 98 88\n",
      "Line: 185 Female 41 99 39\n",
      "Line: 186 Male 30 99 97\n",
      "Line: 187 Female 54 101 24\n",
      "Line: 188 Male 28 101 68\n",
      "Line: 189 Female 41 103 17\n",
      "Line: 190 Female 36 103 85\n",
      "Line: 191 Female 34 103 23\n",
      "Line: 192 Female 32 103 69\n",
      "Line: 193 Male 33 113 8\n",
      "Line: 194 Female 38 113 91\n",
      "Line: 195 Female 47 120 16\n",
      "Line: 196 Female 35 120 79\n",
      "Line: 197 Female 45 126 28\n",
      "Line: 198 Male 32 126 74\n",
      "Line: 199 Male 32 137 18\n",
      "Line: 200 Male 30 137 83\n"
     ]
    }
   ],
   "source": [
    "# is , the only allowed delimiter? It is the most common one, but we are not restricted to it\n",
    "# let's deal with a file with the same content but different delimiter\n",
    "file_path = '/Users/giannidicaro/.spyder-py3/csv/Mall_Customers-d2.csv'\n",
    "f2_csv = open(file_path)\n",
    "csv_data = csv.reader(f2_csv, delimiter=';')\n",
    "line_count = 0\n",
    "for row in csv_data:\n",
    "    print('Line: {}'.format(' '.join(row)))\n",
    "    line_count += 1\n",
    "f2_csv.close()\n",
    "# no problems at all, we get the same output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delimiter must be 1-charater string!\n"
     ]
    }
   ],
   "source": [
    "# what about a delimiter with more than one single character?\n",
    "file_path = '/Users/giannidicaro/.spyder-py3/csv/Mall_Customers-d3.csv'\n",
    "f3_csv = open(file_path)\n",
    "try:\n",
    "    csv_data = csv.reader(f3_csv, delimiter='--')\n",
    "except:\n",
    "    print(\"Delimiter must be 1-charater string!\")\n",
    "else:\n",
    "    line_count = 0\n",
    "    for row in csv_data:\n",
    "        print('Line: {}'.format(' '.join(row)))\n",
    "        line_count += 1\n",
    "finally:\n",
    "    f3_csv.close()\n",
    "# TypeError! delimiter must be 1-character string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: name - address - date joined (#fields: 3)\n",
      "Line: john smith - 1132 Anywhere Lane Hoboken NJ -  07030 - Jan 4 (#fields: 4)\n",
      "Line: erica meyers - 1234 Smith Lane Hoboken NJ -  07030 -   March 2 (#fields: 4)\n",
      "Line: ann mcdonald -  9223 Yoda Lane Pythonopolis CA -  90001 - April 1 (#fields: 4)\n"
     ]
    }
   ],
   "source": [
    "# What if I want to use commas but the fields contain commas in their data?\n",
    "# Let's look at file employee_adresses.csv\n",
    "# each record contains three fields:\n",
    "# name, adress, date joined\n",
    "# Unfortunately, the field address contains commas, as it is common defining addresses\n",
    "# What happens if we try to read the file?\n",
    "file_path = '/Users/giannidicaro/.spyder-py3/csv/employee_addresses.csv'\n",
    "f_csv = open(file_path)\n",
    "csv_data = csv.reader(f_csv, delimiter=',')\n",
    "line_count = 0\n",
    "for row in csv_data:\n",
    "    print('Line: {} (#fields: {})'.format(' - '.join(row), len(row)))\n",
    "    line_count += 1\n",
    "f_csv.close()\n",
    "# as expected, the number of fields in each row is 4 instead of being 3, since every comma\n",
    "# in the row is interpreted as a field separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: name - address - date joined (#fields: 3)\n",
      "Line: john smith - 1132 Anywhere Lane Hoboken NJ, 07030 - Jan 4 (#fields: 3)\n",
      "Line: erica meyers - 1234 Smith Lane Hoboken NJ, 07030 -   March 2 (#fields: 3)\n",
      "Line: ann mcdonald -  9223 Yoda Lane Pythonopolis CA, 90001 - April 1 (#fields: 3)\n"
     ]
    }
   ],
   "source": [
    "# How do we deal with this issue?\n",
    "# Three possible strategies, all requiring modifying the original csv file:\n",
    "# 1. Use a different delimiter in the csv file (e.g., ';')\n",
    "# 2. Wrap the data containing commas in quotes: the string between the quotes is not \n",
    "#      evaluated for the delimiter. The character used for quoting needs to be specified by\n",
    "#      the quotechar optional parameter if different from \" which is the default \n",
    "# 3. Escape the delimiter character in the data: adding \\ \"protects\" the character from \n",
    "#          being evaluated as a delimiter. If an escape character is used, it must be \n",
    "#          specified using the escapechar optional parameter.\n",
    "# Strategy 1:         \n",
    "file_path = '/Users/giannidicaro/.spyder-py3/csv/employee_addresses-d2.csv'\n",
    "f_csv = open(file_path)\n",
    "csv_data = csv.reader(f_csv, delimiter=';')\n",
    "line_count = 0\n",
    "for row in csv_data:\n",
    "    print('Line: {} (#fields: {})'.format(' - '.join(row), len(row)))\n",
    "    line_count += 1\n",
    "f_csv.close()\n",
    "# it works as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: name - address - date joined (#fields: 3)\n",
      "Line: john smith - 1132 Anywhere Lane Hoboken NJ, 07030 - Jan 4 (#fields: 3)\n",
      "Line: erica meyers - 1234 Smith Lane Hoboken NJ, 07030 -   March 2 (#fields: 3)\n",
      "Line: ann mcdonald - 9223 Yoda Lane Pythonopolis CA, 90001 - April 1 (#fields: 3)\n"
     ]
    }
   ],
   "source": [
    "# Strategy 2:\n",
    "file_path = '/Users/giannidicaro/.spyder-py3/csv/employee_addresses-quotes.csv'\n",
    "f_csv = open(file_path)\n",
    "csv_data = csv.reader(f_csv, delimiter=',', quotechar='\"')\n",
    "line_count = 0\n",
    "for row in csv_data:\n",
    "    print('Line: {} (#fields: {})'.format(' - '.join(row), len(row)))\n",
    "    line_count += 1\n",
    "f_csv.close()\n",
    "# it works! however, some attention needs to be devoted to the presence of spaces \n",
    "# before or after the quoting character, that would prevent from letting the \n",
    "# character being properly interpreted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: name - address - date joined (#fields: 3)\n",
      "Line: john smith -  1132 Anywhere Lane Hoboken NJ, 07030 - Jan 4 (#fields: 3)\n",
      "Line: erica meyers -  1234 Smith Lane Hoboken NJ, 07030 -   March 2 (#fields: 3)\n",
      "Line: ann mcdonald - 9223 Yoda Lane Pythonopolis CA, 90001 - April 1 (#fields: 3)\n"
     ]
    }
   ],
   "source": [
    "# Strategy 3:\n",
    "file_path = '/Users/giannidicaro/.spyder-py3/csv/employee_addresses-escape.csv'\n",
    "f_csv = open(file_path)\n",
    "csv_data = csv.reader(f_csv, delimiter=',', escapechar='\\\\')\n",
    "line_count = 0\n",
    "for row in csv_data:\n",
    "    print('Line: {} (#fields: {})'.format(' - '.join(row), len(row)))\n",
    "    line_count += 1\n",
    "f_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of object csv_data: <class 'csv.DictReader'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A csv file can be seen as a dictionary: each column has a label, \n",
    "# hence, we can read the csv data file (or, more generically, tabular data)\n",
    "# into an 'ordered dictionary', an dictionary that preserves/remembers the order for entering\n",
    "# the keys. The keays are sorted by the order associated to their entrance in the dictionary.\n",
    "# Each row is an ordered dictionary with respect to the keys/columns\n",
    "# An ordered dictionary is a data type from the module 'collections' that can be constructed\n",
    "# with od = collections.OrderedDict()\n",
    "#\n",
    "file_path = '/Users/giannidicaro/.spyder-py3/csv/biometric_simple.csv'\n",
    "f_csv = open(file_path)\n",
    "csv_data = csv.DictReader(f_csv)\n",
    "print(\"Type of object csv_data: {}\\n\".format(type(csv_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The csv dictionary reader object csv_data is constructed from the first row\n",
    "# of the csv file, that specifies the names of the fields, that is, the common label/key\n",
    "# of each field / column.\n",
    "#\n",
    "# Based on the definition of the keys, csv data are read into an ordered dictionary\n",
    "# where each row is stored in an ordered dictionary of strings: the keys are the strings\n",
    "# defined in the header row and the values are strings representing the column values\n",
    "# \n",
    "# The number and names of the fields/keys can be retrieved by accessing the list .fieldnames\n",
    "# of the dictionary reader\n",
    "#\n",
    "import os \n",
    "\n",
    "num_of_keys = len(csv_data.fieldnames)\n",
    "keys = csv_data.fieldnames\n",
    "stat = os.stat(file_path)\n",
    "size = stat.st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Mall_Customers.csv has size 100 bytes and contains 5 keys: id - name - age - height - weight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the number of records? the reader doesn't know at this stage, \n",
    "# we must read the data first! But we can print out the number of records\n",
    "# and maybe the size of the entire file, to get an idea of how big it will be\n",
    "#\n",
    "print('File {} has size {} bytes and contains {:d} keys: {:s}\\n'.format(file_name, \n",
    "                                                   size, num_of_keys, ' - '.join(keys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 has type <class 'collections.OrderedDict'> and 5 keys\n",
      "Alice    has ID   768, is 20 years old, 1.62m tall, and weights 54.60kg\n",
      "\n",
      "Row 2 has type <class 'collections.OrderedDict'> and 5 keys\n",
      "Freddie  has ID   562, is 21 years old, 1.74m tall, and weights 78.60kg\n",
      "\n",
      "Row 3 has type <class 'collections.OrderedDict'> and 5 keys\n",
      "Bob      has ID   523, is 17 years old, 1.68m tall, and weights 82.00kg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After the creation of the ordered dictionary object, the iterator is positioned at\n",
    "# the first row with actual data\n",
    "# Now we can read / print each line, which is a ordered dictionary with N keys\n",
    "# Let's use the (known) names of columns to make a nice printing\n",
    "line_count = 1\n",
    "for row in csv_data:\n",
    "    print('Row {} has type {} and {} keys'.format(line_count, type(row), len(row)))    \n",
    "    print('{:<8s} has ID {:5d}, is {:2d} years old, {:4.2f}m tall, and weights {:5.2f}kg\\n'.\n",
    "          format(row['name'], int(row['id']), int(row['age']), \n",
    "                 float(row['height'])/100, float(row['weight'])))\n",
    "    line_count += 1\n",
    "#f_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', 'id'),\n",
       "             ('name', 'name'),\n",
       "             ('age', 'age'),\n",
       "             ('height', 'height'),\n",
       "             ('weight', 'weight')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can we get the same nice printing without first opening the file and reading the labels?\n",
    "#\n",
    "# First, let's notice that since we have read the entire file, we need to rewind it, \n",
    "# to go back to the first record. In fact, the instance csv_data is an iterator. \n",
    "# An iterator emits a unit of data on each explicit/implicit invocation of next() on it,\n",
    "# and with the above instructions we have performed an implicit next() call at each\n",
    "# step of the for loop. Therefore, now the iterator is at the end of the file\n",
    "# and it is necessary to rewind the file, and skip the header\n",
    "f_csv.seek(0)\n",
    "next(csv_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice    has ID   768, is 20 years old, 1.62m tall, and weights 54.60kg\n",
      "\n",
      "Freddie  has ID   562, is 21 years old, 1.74m tall, and weights 78.60kg\n",
      "\n",
      "Bob      has ID   523, is 17 years old, 1.68m tall, and weights 82.00kg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# variable keys above is a list with all dictionary keys in order of column insertion, \n",
    "# and we know that in each row keys always keep the same order\n",
    "# print(keys)\n",
    "#\n",
    "line_count = 1\n",
    "for row in csv_data:\n",
    "    print('{:<8s} has ID {:5d}, is {:2d} years old, {:4.2f}m tall, and weights {:5.2f}kg\\n'.\n",
    "          format(row[keys[1]], int(row[keys[0]]), int(row[keys[2]]), \n",
    "                 float(row[keys[3]])/100, float(row[keys[4]])))\n",
    "    line_count += 1\n",
    "#f_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', 'id'),\n",
       "             ('name', 'name'),\n",
       "             ('age', 'age'),\n",
       "             ('height', 'height'),\n",
       "             ('weight', 'weight')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rewind the file again and skip the header\n",
    "f_csv.seek(0)\n",
    "next(csv_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freddie\n",
      "Freddie\n"
     ]
    }
   ],
   "source": [
    "# csv data are tabular data, therefore a 'natural' way to address the data could be:\n",
    "# my_data[row][label/column] which is what we used for instance for matrices, that are tables\n",
    "# We can get this representation by reading all data into a list of ordered dictionaries\n",
    "# and then address individua data based on record/row and label/column\n",
    "#\n",
    "tabular_csv = list(csv_data)  \n",
    "# tabular_csv is a list of records in the form of ordered dictionaries\n",
    "# How do we access the value of field 'name' in record 1?\n",
    "print(tabular_csv[1]['name'])\n",
    "\n",
    "# Using the keys we can also make adopt a label agnostic, more \"pure\" matrix representation:\n",
    "print(tabular_csv[1][keys[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768       Alice     20         162       54.6     \n",
      "\n",
      "562       Freddie    21        174       78.6     \n",
      "\n",
      "523       Bob        17        168       82.0     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's print out all data in the file using this notation, and let's print everything\n",
    "# as it is in the dictionary, that is, as strings. Setting a predefined length in the\n",
    "# format specifier it allows to have a decently nice formatting\n",
    "#\n",
    "for i in range(len(tabular_csv)):\n",
    "    for k in range(num_of_keys):\n",
    "        print('{:9s} '.format(tabular_csv[i][keys[k]]), end='')\n",
    "    print('\\n')\n",
    "\n",
    "f_csv.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
